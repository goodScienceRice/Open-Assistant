{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goodScienceRice/Open-Assistant/blob/main/Knowledge_Embedding_Community_Blog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAhGcMmDuBhU"
      },
      "source": [
        "##Pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect Google Drive"
      ],
      "metadata": {
        "id": "T2q44qwPHhFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VvPAOp-PHl0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBWlsoUXvRYX"
      },
      "source": [
        "###Installing Pinecone Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L13JZlWdqC8Y"
      },
      "outputs": [],
      "source": [
        "!pip install pandas==1.5.3\n",
        "!pip install -qU pinecone-client pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqPNCBD2q2nQ"
      },
      "outputs": [],
      "source": [
        "import pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkqsshKtyFCt"
      },
      "source": [
        "###Installing Other required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIXCL2LTqHMS"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obP1LEVDq2CC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "OPENAI_API_KEY=''\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from time import sleep\n",
        "from uuid import uuid4\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6iI2DuzvDtC"
      },
      "source": [
        "###Pinecone keys configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzFpSE6lq2ki"
      },
      "outputs": [],
      "source": [
        "pinecone.init(api_key=\"\", environment=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He7sIc5_vlfz"
      },
      "source": [
        "###Pinecone Index details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWaeo8LevqZs",
        "outputId": "b95aa45e-5050-4d21-c08b-b076395bd2b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knowledge']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "pinecone.list_indexes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Xm5SEZrBFH",
        "outputId": "9e564c01-b809-4080-e877-27043ad1a6e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 17}},\n",
              " 'total_vector_count': 17}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "pinecone.Index('knowledge').describe_index_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emAM9r3LDlUj"
      },
      "outputs": [],
      "source": [
        "#pinecone.delete_index(\"knowledge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj06JifTM03h"
      },
      "source": [
        "###PDF, CSV, TXT Files are Supported"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVI93jAFyKu6"
      },
      "source": [
        "PDF Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hvgltm4wrDUj"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2\n",
        "import PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfp8CdCRrGpK"
      },
      "outputs": [],
      "source": [
        "# importing required modules\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# creating a pdf reader object\n",
        "reader = PdfReader('stevejobs.pdf') #Replace 'stevejobs.pdf' with your .pdf file\n",
        "\n",
        "# getting a specific page from the pdf file\n",
        "page = reader.pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrqBBO4OrJI4"
      },
      "outputs": [],
      "source": [
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "   text+=page.extract_text()\n",
        "#print(type(text), len(text))\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dksJcalI0UAL"
      },
      "source": [
        "CSV Upload\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cwz3SpForLmZ"
      },
      "outputs": [],
      "source": [
        "# Replace 'Pinecone test - Sheet1.csv' with your .csv file\n",
        "import csv\n",
        "\n",
        "filename = 'Pinecone test - Sheet1.csv'\n",
        "\n",
        "# If you want to store lines in a list:\n",
        "lines_string = \"\"\n",
        "with open(filename, 'r') as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "    for row in reader:\n",
        "        lines_string += ' '.join(row) + \"\\n\"\n",
        "\n",
        "text = lines_string\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvGiQXD55HrJ"
      },
      "source": [
        "TXT Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe0xUMEvrOtL"
      },
      "outputs": [],
      "source": [
        "# Replace 'stevejobs.txt' with your filename\n",
        "with open('stevejobs.txt') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LxaZms3zzb6"
      },
      "source": [
        "###Text Chunking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import TokenTextSplitter\n",
        "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=10)\n",
        "input_chunks = text_splitter.split_text(text)\n",
        "i=0\n",
        "for item in input_chunks:\n",
        "  i+=1\n",
        "  print(f'\\nChunk {i}:\\n')\n",
        "  print(item)\n"
      ],
      "metadata": {
        "id": "hDR80n-bTHHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR3vwWLatkI2",
        "outputId": "6d8b74e7-7a90-4bd9-eac3-698f28ba8e57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "len(input_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkbI4bXizh95"
      },
      "source": [
        "###Embedding Model and Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVG_cuW4ruOu"
      },
      "outputs": [],
      "source": [
        "embed_model = \"text-embedding-ada-002\"\n",
        "batch_size=6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaqSx9134IQ0"
      },
      "source": [
        "###Creating Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eQNRhIprkCK"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(texts):\n",
        "  res = openai.Embedding.create(input=texts, engine=embed_model)\n",
        "  for record in res['data']:\n",
        "    embeds = record['embedding']\n",
        "  return embeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsAGUxo7rnEv"
      },
      "outputs": [],
      "source": [
        "final_chunks=[]\n",
        "final_chunks.extend([{\n",
        "   \"id\": str(uuid4()),\n",
        "   \"text\": input_chunks[i],\n",
        "   \"chunk\": i,\n",
        "   \"knowledge_name\": \"knowledge\", # Replace \"knowledge\" with the your index name\n",
        "   \"embeds\" : create_embeddings(input_chunks[i]),\n",
        "} for i in range(len(input_chunks))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFqy6usetuS1"
      },
      "outputs": [],
      "source": [
        "len(final_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp3iVnAxzOFi"
      },
      "source": [
        "###Pinecone Index creation and Upsert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiOM4NGQt0BP"
      },
      "outputs": [],
      "source": [
        "pinecone.create_index(\"knowledge\", dimension=1536, metric=\"dotproduct\") # Replace \"knowledge\" with the your index name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsLNkdYnrxSR"
      },
      "outputs": [],
      "source": [
        "index = pinecone.Index('knowledge') # Replace \"knowledge\" with the your index name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ir3l49Hrxr3"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(range(0, len(final_chunks), batch_size)):\n",
        "      # find end of batch\n",
        "  i_end = min(len(final_chunks), i + batch_size) #1\n",
        "  meta_batch = final_chunks[i:i_end]\n",
        "  batch_id = [x['id'] for x in meta_batch]\n",
        "      # get texts to encode\n",
        "  texts = [x['text'] for x in meta_batch]\n",
        "      # create embeddings (try-except added to avoid RateLimitError)\n",
        "  try:\n",
        "    res = openai.Embedding.create(input=texts, engine=embed_model)\n",
        "  except:\n",
        "    done = False\n",
        "    while not done:\n",
        "      sleep(5)\n",
        "      try:\n",
        "        res = openai.Embedding.create(input=texts, engine=embed_model)\n",
        "        done = True\n",
        "      except:\n",
        "        pass\n",
        "  embeds = [record['embedding'] for record in res['data']]\n",
        "      # cleanup metadata\n",
        "  meta_batch = [{\n",
        "    'text': x['text'],\n",
        "    'chunk': x['chunk'],\n",
        "    'knowledge_name': x['knowledge_name'], # Replace \"knowledge\" with the your index name\n",
        "  } for x in meta_batch]\n",
        "  to_upsert = list(zip(batch_id, embeds, meta_batch))\n",
        "  print(to_upsert)\n",
        "      # upsert to Pinecone\n",
        "  index.upsert(vectors=to_upsert)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.Index('knowledge').describe_index_stats() # Replace \"knowledge\" with the your index name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtNAgl27jZPO",
        "outputId": "ed451d51-3a3e-4ed1-993a-61ab640f1133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 206}},\n",
              " 'total_vector_count': 206}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VhB2csP4ThRj",
        "zYKd-5ZiTlgQ",
        "SBWlsoUXvRYX",
        "6rJyiH2JtQvN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}